{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: #to see matplotlib inline in notebook\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns #Another library for visualization\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set_style(\"ticks\") #to see seaborn inline in notebook\n",
    "%matplotlib inline #to see matplotlib inline in notebook\n",
    "plt.style.use(\"seaborn-poster\")  # make bigger plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.4</td>\n",
       "      <td>141.1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>53.2</td>\n",
       "      <td>1488</td>\n",
       "      <td>61</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.5</td>\n",
       "      <td>48</td>\n",
       "      <td>5100</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>5151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.6</td>\n",
       "      <td>144.6</td>\n",
       "      <td>63.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>1713</td>\n",
       "      <td>92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.6</td>\n",
       "      <td>58</td>\n",
       "      <td>4800</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>6479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.6</td>\n",
       "      <td>144.6</td>\n",
       "      <td>63.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>1819</td>\n",
       "      <td>92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.2</td>\n",
       "      <td>76</td>\n",
       "      <td>6000</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>6855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1837</td>\n",
       "      <td>79</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.07</td>\n",
       "      <td>10.1</td>\n",
       "      <td>60</td>\n",
       "      <td>5500</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1940</td>\n",
       "      <td>92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.2</td>\n",
       "      <td>76</td>\n",
       "      <td>6000</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>6529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wheel-base  length  width  height  curb-weight  engine-size  bore  stroke  \\\n",
       "0        88.4   141.1   60.3    53.2         1488           61  2.91    3.03   \n",
       "1        86.6   144.6   63.9    50.8         1713           92  2.91    3.41   \n",
       "2        86.6   144.6   63.9    50.8         1819           92  2.91    3.41   \n",
       "3        93.7   150.0   64.0    52.6         1837           79  2.91    3.07   \n",
       "4        93.7   150.0   64.0    52.6         1940           92  2.91    3.41   \n",
       "\n",
       "   compression-ratio  horsepower  peak-rpm  city-mpg  highway-mpg  price  \n",
       "0                9.5          48      5100        47           53   5151  \n",
       "1                9.6          58      4800        49           54   6479  \n",
       "2                9.2          76      6000        31           38   6855  \n",
       "3               10.1          60      5500        38           42   5399  \n",
       "4                9.2          76      6000        30           34   6529  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Car_price_PLR.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train of x:  (127, 13)\n",
      "Train of y: (127,)\n",
      "Test of x: (32, 13)\n",
      "Test of y: (32,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=36)\n",
    "print(\"Train of x: \",x_train.shape) # x is always 2d so that (40,1)\n",
    "print(\"Train of y:\",y_train.shape) # y is always 1d so that (40,)\n",
    "print(\"Test of x:\",x_test.shape)\n",
    "print('Test of y:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  88.4   141.1    60.3    53.2  1488.     61.      2.91    3.03    9.5\n",
      "    48.   5100.     47.     53.  ]\n",
      " [  86.6   144.6    63.9    50.8  1713.     92.      2.91    3.41    9.6\n",
      "    58.   4800.     49.     54.  ]\n",
      " [  86.6   144.6    63.9    50.8  1819.     92.      2.91    3.41    9.2\n",
      "    76.   6000.     31.     38.  ]\n",
      " [  93.7   150.     64.     52.6  1837.     79.      2.91    3.07   10.1\n",
      "    60.   5500.     38.     42.  ]\n",
      " [  93.7   150.     64.     52.6  1940.     92.      2.91    3.41    9.2\n",
      "    76.   6000.     30.     34.  ]\n",
      " [  93.7   150.     64.     52.6  1956.     92.      2.91    3.41    9.2\n",
      "    76.   6000.     30.     34.  ]\n",
      " [  94.5   155.9    63.6    52.   1874.     90.      3.03    3.11    9.6\n",
      "    70.   5400.     38.     43.  ]\n",
      " [  93.7   156.9    63.4    53.7  2050.     97.      3.62    2.36    9.\n",
      "    69.   4900.     31.     36.  ]\n",
      " [  96.5   157.1    63.9    58.3  2024.     92.      2.92    3.41    9.2\n",
      "    76.   6000.     30.     34.  ]\n",
      " [  93.    157.3    63.8    50.8  2145.     98.      3.03    3.39    7.6\n",
      "   102.   5500.     24.     30.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression() \n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8480169747873415\n",
      "Test Score: 0.8285830310360867\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score:\",regressor.score(x_train,y_train))\n",
    "print(\"Test Score:\",regressor.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  column\n",
      "Linear Regression\n",
      "R2 of train: 0.5946534503861031\n",
      "R2 of test: 0.2904418667736296\n",
      "\n",
      "2  column\n",
      "Linear Regression\n",
      "R2 of train: 0.5874115257309271\n",
      "R2 of test: 0.539100432854064\n",
      "\n",
      "3  column\n",
      "Linear Regression\n",
      "R2 of train: 0.6841224372514207\n",
      "R2 of test: 0.8240670521198157\n",
      "\n",
      "4  column\n",
      "Linear Regression\n",
      "R2 of train: 0.06812077412745243\n",
      "R2 of test: 0.021211525756941074\n",
      "\n",
      "5  column\n",
      "Linear Regression\n",
      "R2 of train: 0.7882611301737485\n",
      "R2 of test: 0.8387402250738005\n",
      "\n",
      "6  column\n",
      "Linear Regression\n",
      "R2 of train: 0.7223029385442026\n",
      "R2 of test: 0.6462477166897587\n",
      "\n",
      "7  column\n",
      "Linear Regression\n",
      "R2 of train: 0.3299277413769338\n",
      "R2 of test: 0.0744796648198296\n",
      "\n",
      "8  column\n",
      "Linear Regression\n",
      "R2 of train: 0.024593558346898137\n",
      "R2 of test: 0.02778257667037831\n",
      "\n",
      "9  column\n",
      "Linear Regression\n",
      "R2 of train: 0.03196108607799086\n",
      "R2 of test: 0.0820461670585273\n",
      "\n",
      "10  column\n",
      "Linear Regression\n",
      "R2 of train: 0.5601037599396204\n",
      "R2 of test: 0.6452660529672234\n",
      "\n",
      "11  column\n",
      "Linear Regression\n",
      "R2 of train: 0.04219270451082913\n",
      "R2 of test: -0.031368034266988865\n",
      "\n",
      "12  column\n",
      "Linear Regression\n",
      "R2 of train: 0.45799198316331646\n",
      "R2 of test: 0.5561643280193904\n",
      "\n",
      "13  column\n",
      "Linear Regression\n",
      "R2 of train: 0.5049377551596348\n",
      "R2 of test: 0.5655485641087041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for col in range(13):\n",
    "    temp = x_train[:,col:col+1]\n",
    "    test = x_test[:,col:col+1]\n",
    "    reg=LinearRegression() \n",
    "    reg.fit(temp,y_train)\n",
    "    print(col+1,\" column\")\n",
    "    print(\"Linear Regression\")\n",
    "    print(\"R2 of train:\",reg.score(temp,y_train))\n",
    "    print(\"R2 of test:\",reg.score(test,y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4,7,8,9,11 columns can be removed for MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:,[0,1,2,4,5,9,12]] # Removing 4,7,8,9,11 column from the x_train array\n",
    "# Don't run more than 1 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 115.6,  202.6,   71.7, 3770. ,  183. ,  123. ,   25. ],\n",
       "       [ 109.1,  188.8,   68.9, 3062. ,  141. ,  114. ,   25. ],\n",
       "       [ 109.1,  188.8,   68.9, 3217. ,  145. ,  106. ,   27. ],\n",
       "       [  93.7,  167.3,   63.8, 1989. ,   90. ,   68. ,   38. ],\n",
       "       [ 107.9,  186.7,   68.4, 3252. ,  152. ,   95. ,   33. ],\n",
       "       [  93.7,  150. ,   64. , 1837. ,   79. ,   60. ,   42. ],\n",
       "       [  93.7,  157.3,   63.8, 1918. ,   90. ,   68. ,   41. ],\n",
       "       [ 113. ,  199.6,   69.6, 4066. ,  258. ,  176. ,   19. ],\n",
       "       [  94.5,  168.7,   64. , 2265. ,   98. ,  112. ,   29. ],\n",
       "       [  96.5,  175.4,   65.2, 2465. ,  110. ,  101. ,   28. ],\n",
       "       [  86.6,  144.6,   63.9, 1819. ,   92. ,   76. ,   38. ],\n",
       "       [  96.5,  167.5,   65.2, 2289. ,  110. ,   86. ,   33. ],\n",
       "       [  93.7,  157.3,   63.8, 1876. ,   90. ,   68. ,   38. ],\n",
       "       [ 104.3,  188.8,   67.2, 3045. ,  130. ,  162. ,   22. ],\n",
       "       [  94.5,  168.7,   64. , 2300. ,   98. ,  112. ,   29. ],\n",
       "       [ 104.3,  188.8,   67.2, 3157. ,  130. ,  162. ,   22. ],\n",
       "       [ 101.2,  176.8,   64.8, 2765. ,  164. ,  121. ,   28. ],\n",
       "       [  94.5,  165.6,   63.8, 2028. ,   97. ,   69. ,   37. ],\n",
       "       [  93.7,  157.3,   63.8, 1967. ,   90. ,   68. ,   38. ],\n",
       "       [ 100.4,  184.6,   66.5, 3296. ,  181. ,  152. ,   22. ],\n",
       "       [  94.5,  170.2,   63.8, 2024. ,   97. ,   69. ,   37. ],\n",
       "       [  99.1,  186.6,   66.5, 2808. ,  121. ,  160. ,   26. ],\n",
       "       [  94.5,  165.3,   63.8, 1918. ,   97. ,   69. ,   37. ],\n",
       "       [  93.1,  166.8,   64.2, 1950. ,   91. ,   68. ,   38. ],\n",
       "       [  99.4,  176.6,   66.4, 2824. ,  136. ,  115. ,   22. ],\n",
       "       [  99.1,  186.6,   66.5, 2695. ,  121. ,  110. ,   28. ],\n",
       "       [  97.3,  171.7,   65.5, 2275. ,  109. ,   85. ,   34. ],\n",
       "       [ 103.3,  174.6,   64.6, 2535. ,  122. ,   88. ,   30. ],\n",
       "       [ 104.9,  175. ,   66.1, 2670. ,  140. ,  120. ,   27. ],\n",
       "       [ 102.9,  183.5,   67.7, 3016. ,  171. ,  161. ,   24. ],\n",
       "       [  98.4,  176.2,   65.6, 2679. ,  146. ,  116. ,   30. ],\n",
       "       [  97.2,  173.4,   65.2, 2324. ,  120. ,   97. ,   34. ],\n",
       "       [  95.7,  166.3,   64.4, 2081. ,   98. ,   70. ,   37. ],\n",
       "       [  93.7,  157.3,   63.8, 1876. ,   90. ,   68. ,   41. ],\n",
       "       [  98.8,  177.8,   66.5, 2385. ,  122. ,   84. ,   32. ],\n",
       "       [ 104.3,  188.8,   67.2, 2935. ,  141. ,  114. ,   28. ],\n",
       "       [  98.4,  176.2,   65.6, 2714. ,  146. ,  116. ,   30. ],\n",
       "       [ 107.9,  186.7,   68.4, 3075. ,  120. ,   95. ,   24. ],\n",
       "       [ 104.3,  188.8,   67.2, 3034. ,  141. ,  114. ,   28. ],\n",
       "       [ 101.2,  176.8,   64.8, 2395. ,  108. ,  101. ,   29. ],\n",
       "       [  95.7,  169.7,   63.6, 3110. ,   92. ,   62. ,   32. ],\n",
       "       [  99.2,  178.5,   67.9, 3139. ,  181. ,  160. ,   25. ],\n",
       "       [  98.8,  177.8,   66.5, 2385. ,  122. ,   84. ,   32. ],\n",
       "       [  97.3,  171.7,   65.5, 2264. ,   97. ,   52. ,   46. ],\n",
       "       [  94.5,  168.7,   64. , 2169. ,   98. ,   70. ,   34. ],\n",
       "       [  95.7,  166.3,   64.4, 2275. ,  110. ,   56. ,   36. ],\n",
       "       [  93.7,  157.9,   63.6, 2120. ,  108. ,   73. ,   31. ],\n",
       "       [  96.3,  173. ,   65.4, 2370. ,  110. ,  116. ,   30. ],\n",
       "       [ 100.4,  184.6,   66.5, 3060. ,  181. ,  152. ,   25. ],\n",
       "       [  97.2,  172. ,   65.4, 2145. ,  108. ,   82. ,   37. ],\n",
       "       [  93.7,  157.3,   63.8, 2128. ,   98. ,  102. ,   30. ],\n",
       "       [  94.5,  168.7,   64. , 2204. ,   98. ,   70. ,   34. ],\n",
       "       [ 110. ,  190.9,   70.3, 3515. ,  183. ,  123. ,   25. ],\n",
       "       [  88.4,  141.1,   60.3, 1488. ,   61. ,   48. ,   53. ],\n",
       "       [  93. ,  157.3,   63.8, 2145. ,   98. ,  102. ,   30. ],\n",
       "       [ 103.3,  174.6,   64.6, 2535. ,  122. ,   88. ,   30. ],\n",
       "       [ 104.5,  187.8,   66.5, 3131. ,  171. ,  156. ,   24. ],\n",
       "       [ 102.4,  175.6,   66.5, 2414. ,  122. ,   92. ,   32. ],\n",
       "       [ 102.4,  175.6,   66.5, 2458. ,  122. ,   92. ,   32. ],\n",
       "       [  93.7,  157.3,   64.4, 1918. ,   92. ,   68. ,   41. ],\n",
       "       [  96.5,  157.1,   63.9, 2024. ,   92. ,   76. ,   34. ],\n",
       "       [  96.3,  172.4,   65.4, 2405. ,  122. ,   88. ,   32. ],\n",
       "       [ 102.4,  175.6,   66.5, 2480. ,  110. ,   73. ,   33. ],\n",
       "       [  98.8,  177.8,   66.5, 2425. ,  122. ,   84. ,   32. ],\n",
       "       [  93.7,  157.3,   63.8, 1967. ,   90. ,   68. ,   38. ],\n",
       "       [  95.9,  173.2,   66.3, 2811. ,  156. ,  145. ,   24. ],\n",
       "       [  94.5,  165.3,   63.8, 1889. ,   97. ,   69. ,   37. ],\n",
       "       [ 109.1,  188.8,   68.9, 2952. ,  141. ,  114. ,   28. ],\n",
       "       [  97.3,  171.7,   65.5, 2212. ,  109. ,   85. ,   34. ],\n",
       "       [  97.2,  173.4,   65.2, 2302. ,  120. ,   97. ,   34. ],\n",
       "       [  93.7,  156.9,   63.4, 2050. ,   97. ,   69. ,   36. ],\n",
       "       [ 105.8,  192.7,   71.4, 2844. ,  136. ,  110. ,   25. ],\n",
       "       [ 109.1,  188.8,   68.8, 3049. ,  141. ,  160. ,   25. ],\n",
       "       [  94.5,  165.3,   63.8, 1971. ,   97. ,   69. ,   37. ],\n",
       "       [  96.3,  172.4,   65.4, 2365. ,  122. ,   88. ,   32. ],\n",
       "       [  95.7,  166.3,   64.4, 2140. ,   98. ,   70. ,   34. ],\n",
       "       [  95.7,  169.7,   63.6, 2280. ,   92. ,   62. ,   37. ],\n",
       "       [  93.7,  150. ,   64. , 1956. ,   92. ,   76. ,   34. ],\n",
       "       [ 101.2,  176.8,   64.8, 2710. ,  164. ,  121. ,   28. ],\n",
       "       [  94.5,  165.7,   64. , 2221. ,  109. ,   90. ,   29. ],\n",
       "       [  95.7,  166.3,   64.4, 2094. ,   98. ,   70. ,   47. ],\n",
       "       [  97. ,  172. ,   65.4, 2385. ,  108. ,   82. ,   25. ],\n",
       "       [ 101.2,  176.8,   64.8, 2395. ,  108. ,  101. ,   29. ],\n",
       "       [  98.4,  176.2,   65.6, 2536. ,  146. ,  116. ,   30. ],\n",
       "       [ 108. ,  186.7,   68.3, 3130. ,  134. ,  142. ,   24. ],\n",
       "       [ 104.3,  188.8,   67.2, 3042. ,  141. ,  114. ,   28. ],\n",
       "       [  96.5,  163.4,   64. , 2010. ,   92. ,   76. ,   34. ],\n",
       "       [  97.3,  171.7,   65.5, 2319. ,   97. ,   68. ,   42. ],\n",
       "       [  98.4,  176.2,   65.6, 2975. ,  146. ,  116. ,   30. ],\n",
       "       [  93.7,  157.3,   63.8, 1989. ,   90. ,   68. ,   38. ],\n",
       "       [  94.5,  155.9,   63.6, 1874. ,   90. ,   70. ,   43. ],\n",
       "       [ 106.7,  187.5,   70.3, 3495. ,  183. ,  123. ,   25. ],\n",
       "       [  99.1,  186.6,   66.5, 2758. ,  121. ,  110. ,   28. ],\n",
       "       [  97.3,  171.7,   65.5, 2209. ,  109. ,   85. ,   34. ],\n",
       "       [  95.7,  158.7,   63.6, 2015. ,   92. ,   62. ,   38. ],\n",
       "       [  98.8,  177.8,   66.5, 2410. ,  122. ,   84. ,   32. ],\n",
       "       [  96.3,  172.4,   65.4, 2403. ,  110. ,  116. ,   30. ],\n",
       "       [  94.5,  165.3,   63.8, 2017. ,  103. ,   55. ,   50. ],\n",
       "       [  93.7,  157.3,   64.4, 2004. ,   92. ,   68. ,   38. ],\n",
       "       [  96.3,  172.4,   65.4, 2403. ,  110. ,  116. ,   30. ],\n",
       "       [  97. ,  173.5,   65.4, 2290. ,  108. ,   82. ,   32. ],\n",
       "       [  99.1,  186.6,   66.5, 2658. ,  121. ,  110. ,   28. ],\n",
       "       [  98.4,  176.2,   65.6, 2540. ,  146. ,  116. ,   30. ],\n",
       "       [ 107.9,  186.7,   68.4, 3075. ,  120. ,   97. ,   24. ],\n",
       "       [  98.8,  177.8,   66.5, 2410. ,  122. ,   84. ,   32. ],\n",
       "       [  95.7,  158.7,   63.6, 1985. ,   92. ,   62. ,   39. ],\n",
       "       [  97.3,  171.7,   65.5, 2261. ,   97. ,   52. ,   46. ],\n",
       "       [  95.7,  158.7,   63.6, 2040. ,   92. ,   62. ,   38. ],\n",
       "       [  96.5,  175.4,   65.2, 2304. ,  110. ,   86. ,   33. ],\n",
       "       [  93.7,  157.3,   63.8, 2128. ,   98. ,  102. ,   30. ],\n",
       "       [  93.1,  159.1,   64.2, 1905. ,   91. ,   68. ,   38. ],\n",
       "       [  96.6,  180.3,   70.5, 3685. ,  234. ,  155. ,   18. ],\n",
       "       [  96.3,  173. ,   65.4, 2328. ,  122. ,   88. ,   32. ],\n",
       "       [ 104.3,  188.8,   67.2, 2912. ,  141. ,  114. ,   28. ],\n",
       "       [ 102.9,  183.5,   67.7, 2976. ,  171. ,  161. ,   24. ],\n",
       "       [  98.4,  176.2,   65.6, 2551. ,  146. ,  116. ,   30. ],\n",
       "       [  86.6,  144.6,   63.9, 1713. ,   92. ,   58. ,   54. ],\n",
       "       [  95.1,  162.4,   63.8, 2008. ,   97. ,   69. ,   37. ],\n",
       "       [ 109.1,  188.8,   68.9, 3012. ,  173. ,  134. ,   23. ],\n",
       "       [  96.9,  173.6,   65.4, 2650. ,  108. ,  111. ,   23. ],\n",
       "       [  94.5,  170.2,   63.8, 2037. ,   97. ,   69. ,   37. ],\n",
       "       [ 107.9,  186.7,   68.4, 3197. ,  152. ,   95. ,   33. ],\n",
       "       [  94.5,  165.3,   63.8, 1951. ,   97. ,   69. ,   37. ],\n",
       "       [ 107.9,  186.7,   68.4, 3252. ,  152. ,   95. ,   33. ],\n",
       "       [  95.7,  166.3,   64.4, 2275. ,  110. ,   56. ,   47. ],\n",
       "       [ 102.4,  175.6,   66.5, 2326. ,  122. ,   92. ,   34. ],\n",
       "       [ 107.9,  186.7,   68.4, 3020. ,  120. ,   97. ,   24. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test[:,[0,1,2,4,5,9,12]] # Removing 4,7,8,9,11 column from the x_test array\n",
    "# Don't run more than 1 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8292178665602172\n",
      "Test Score: 0.849574742291106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor_after_removed_MLR=LinearRegression() \n",
    "regressor_after_removed_MLR.fit(x_train,y_train)\n",
    "print(\"Train Score:\",regressor_after_removed_MLR.score(x_train,y_train))\n",
    "print(\"Test Score:\",regressor_after_removed_MLR.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLR \n",
    "Load the enter dataset newly below\n",
    "so that above changes in x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.4</td>\n",
       "      <td>141.1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>53.2</td>\n",
       "      <td>1488</td>\n",
       "      <td>61</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.5</td>\n",
       "      <td>48</td>\n",
       "      <td>5100</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>5151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.6</td>\n",
       "      <td>144.6</td>\n",
       "      <td>63.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>1713</td>\n",
       "      <td>92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.6</td>\n",
       "      <td>58</td>\n",
       "      <td>4800</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>6479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.6</td>\n",
       "      <td>144.6</td>\n",
       "      <td>63.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>1819</td>\n",
       "      <td>92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.2</td>\n",
       "      <td>76</td>\n",
       "      <td>6000</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>6855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1837</td>\n",
       "      <td>79</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.07</td>\n",
       "      <td>10.1</td>\n",
       "      <td>60</td>\n",
       "      <td>5500</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1940</td>\n",
       "      <td>92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.2</td>\n",
       "      <td>76</td>\n",
       "      <td>6000</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>6529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wheel-base  length  width  height  curb-weight  engine-size  bore  stroke  \\\n",
       "0        88.4   141.1   60.3    53.2         1488           61  2.91    3.03   \n",
       "1        86.6   144.6   63.9    50.8         1713           92  2.91    3.41   \n",
       "2        86.6   144.6   63.9    50.8         1819           92  2.91    3.41   \n",
       "3        93.7   150.0   64.0    52.6         1837           79  2.91    3.07   \n",
       "4        93.7   150.0   64.0    52.6         1940           92  2.91    3.41   \n",
       "\n",
       "   compression-ratio  horsepower  peak-rpm  city-mpg  highway-mpg  price  \n",
       "0                9.5          48      5100        47           53   5151  \n",
       "1                9.6          58      4800        49           54   6479  \n",
       "2                9.2          76      6000        31           38   6855  \n",
       "3               10.1          60      5500        38           42   5399  \n",
       "4                9.2          76      6000        30           34   6529  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv(\"Car_price_PLR.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train of x:  (127, 13)\n",
      "Train of y: (127,)\n",
      "Test of x: (32, 13)\n",
      "Test of y: (32,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=36)\n",
    "print(\"Train of x: \",x_train.shape) # x is always 2d so that (40,1)\n",
    "print(\"Train of y:\",y_train.shape) # y is always 1d so that (40,)\n",
    "print(\"Test of x:\",x_test.shape)\n",
    "print('Test of y:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.5946534503861031\n",
      "Test Score: 0.2904418667736296\n",
      "Degree 2\n",
      "Train Score: 0.612012823931462\n",
      "Test Score: 0.34774863201344264\n",
      "Degree 3\n",
      "Train Score: 0.6058296382636245\n",
      "Test Score: 0.3149608415774725\n",
      "\n",
      "1  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.5874115257309269\n",
      "Test Score: 0.5391004328540647\n",
      "Degree 2\n",
      "Train Score: 0.6753780721901641\n",
      "Test Score: 0.5731470599453243\n",
      "Degree 3\n",
      "Train Score: 0.623805101925459\n",
      "Test Score: 0.5581115454095275\n",
      "\n",
      "2  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.6841224372514205\n",
      "Test Score: 0.8240670521198157\n",
      "Degree 2\n",
      "Train Score: 0.7091839546168408\n",
      "Test Score: 0.83057457039808\n",
      "Degree 3\n",
      "Train Score: 0.6937424410807683\n",
      "Test Score: 0.8307812559280807\n",
      "\n",
      "3  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.06812077412745243\n",
      "Test Score: 0.021211525756941074\n",
      "Degree 2\n",
      "Train Score: 0.07601602953251363\n",
      "Test Score: -0.0810370239096736\n",
      "Degree 3\n",
      "Train Score: 0.06562923218970085\n",
      "Test Score: 0.0366602154180129\n",
      "\n",
      "4  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.7882611301737485\n",
      "Test Score: 0.8387402250738005\n",
      "Degree 2\n",
      "Train Score: 0.8228321230906033\n",
      "Test Score: 0.8264281633917525\n",
      "Degree 3\n",
      "Train Score: 0.8225273120107429\n",
      "Test Score: 0.8220225994334895\n",
      "\n",
      "5  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.7223029385442025\n",
      "Test Score: 0.6462477166897587\n",
      "Degree 2\n",
      "Train Score: 0.7233357807222203\n",
      "Test Score: 0.6305598757047076\n",
      "Degree 3\n",
      "Train Score: 0.6423690592760349\n",
      "Test Score: 0.5446501408922799\n",
      "\n",
      "6  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.3299277413769338\n",
      "Test Score: 0.0744796648198296\n",
      "Degree 2\n",
      "Train Score: 0.3322879114568874\n",
      "Test Score: 0.022165764630235008\n",
      "Degree 3\n",
      "Train Score: 0.3247517978940204\n",
      "Test Score: 0.1165962200052556\n",
      "\n",
      "7  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.024593558346898137\n",
      "Test Score: 0.02778257667037831\n",
      "Degree 2\n",
      "Train Score: 0.09241742587199098\n",
      "Test Score: 0.07752244120963214\n",
      "Degree 3\n",
      "Train Score: 0.03891534508245298\n",
      "Test Score: 0.04485716062803857\n",
      "\n",
      "8  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.03196108607799086\n",
      "Test Score: 0.0820461670585273\n",
      "Degree 2\n",
      "Train Score: 0.03667296174578838\n",
      "Test Score: 0.0950954808900446\n",
      "Degree 3\n",
      "Train Score: 0.03591717576562481\n",
      "Test Score: 0.09217005088855612\n",
      "\n",
      "9  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.5601037599396204\n",
      "Test Score: 0.6452660529672234\n",
      "Degree 2\n",
      "Train Score: 0.5640974426603805\n",
      "Test Score: 0.7089127216378748\n",
      "Degree 3\n",
      "Train Score: 0.49927430565760045\n",
      "Test Score: 0.32231516788250447\n",
      "\n",
      "10  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.042192704510829016\n",
      "Test Score: -0.031368034266988865\n",
      "Degree 2\n",
      "Train Score: 0.05294886403782917\n",
      "Test Score: -0.04525297147642715\n",
      "Degree 3\n",
      "Train Score: 0.03505401652006457\n",
      "Test Score: -0.02417769934743408\n",
      "\n",
      "11  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.45799198316331646\n",
      "Test Score: 0.5561643280193904\n",
      "Degree 2\n",
      "Train Score: 0.5580064551933416\n",
      "Test Score: 0.6677374124908751\n",
      "Degree 3\n",
      "Train Score: 0.2821693914738118\n",
      "Test Score: 0.3344060193747356\n",
      "\n",
      "12  column PLR\n",
      "Degree 1 or Linear Regression\n",
      "Train Score: 0.5049377551596348\n",
      "Test Score: 0.5655485641087041\n",
      "Degree 2\n",
      "Train Score: 0.6319818786666929\n",
      "Test Score: 0.6785510617470394\n",
      "Degree 3\n",
      "Train Score: 0.33155528539630497\n",
      "Test Score: 0.37701630134043895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "for col in range(13):\n",
    "    temp = x_train[:,col:col+1]\n",
    "    test = x_test[:,col:col+1]\n",
    "    poly_reg=PolynomialFeatures(degree=3) \n",
    "    # instead \n",
    "    temp_poly=poly_reg.fit_transform(temp)\n",
    "    test_poly=poly_reg.fit_transform(test)\n",
    "    reg_poly=LinearRegression()\n",
    "    print(col,\" column PLR\")\n",
    "    print(\"Degree 1 or Linear Regression\")\n",
    "    reg_poly.fit(temp_poly[:,1:2],y_train)\n",
    "    print(\"Train Score:\",reg_poly.score(temp_poly[:,1:2],y_train))\n",
    "    print(\"Test Score:\",reg_poly.score(test_poly[:,1:2],y_test))\n",
    "    print(\"Degree 2\")\n",
    "    reg_poly.fit(temp_poly[:,2:],y_train)\n",
    "    print(\"Train Score:\",reg_poly.score(temp_poly[:,2:],y_train))\n",
    "    print(\"Test Score:\",reg_poly.score(test_poly[:,2:],y_test))\n",
    "    print(\"Degree 3\")\n",
    "    reg_poly.fit(temp_poly[:,3:],y_train)\n",
    "    print(\"Train Score:\",reg_poly.score(temp_poly[:,3:],y_train))\n",
    "    print(\"Test Score:\",reg_poly.score(test_poly[:,3:],y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have to remove some columns based on the above results\n",
    "## Columns : Degree\n",
    "## 0,1,2,4,9,11,12 : 2\n",
    "## 5 : 1\n",
    "## 3,6,7,8,10 : remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_5thcolumn=x_train[:,5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:,[0,1,2,4,9,11,12]] # All this have score: 2 based on the above result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   13363.36,    41046.76,     5140.89, 14212900.  ,    15129.  ,\n",
       "             484.  ,      625.  ],\n",
       "       [   11902.81,    35645.44,     4747.21,  9375844.  ,    12996.  ,\n",
       "             361.  ,      625.  ],\n",
       "       [   11902.81,    35645.44,     4747.21, 10349089.  ,    11236.  ,\n",
       "             676.  ,      729.  ],\n",
       "       [    8779.69,    27989.29,     4070.44,  3956121.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [   11642.41,    34856.89,     4678.56, 10575504.  ,     9025.  ,\n",
       "             784.  ,     1089.  ],\n",
       "       [    8779.69,    22500.  ,     4096.  ,  3374569.  ,     3600.  ,\n",
       "            1444.  ,     1764.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  3678724.  ,     4624.  ,\n",
       "            1369.  ,     1681.  ],\n",
       "       [   12769.  ,    39840.16,     4844.16, 16532356.  ,    30976.  ,\n",
       "             225.  ,      361.  ],\n",
       "       [    8930.25,    28459.69,     4096.  ,  5130225.  ,    12544.  ,\n",
       "             676.  ,      841.  ],\n",
       "       [    9312.25,    30765.16,     4251.04,  6076225.  ,    10201.  ,\n",
       "             576.  ,      784.  ],\n",
       "       [    7499.56,    20909.16,     4083.21,  3308761.  ,     5776.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9312.25,    28056.25,     4251.04,  5239521.  ,     7396.  ,\n",
       "             729.  ,     1089.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  3519376.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [   10878.49,    35645.44,     4515.84,  9272025.  ,    26244.  ,\n",
       "             289.  ,      484.  ],\n",
       "       [    8930.25,    28459.69,     4096.  ,  5290000.  ,    12544.  ,\n",
       "             676.  ,      841.  ],\n",
       "       [   10878.49,    35645.44,     4515.84,  9966649.  ,    26244.  ,\n",
       "             289.  ,      484.  ],\n",
       "       [   10241.44,    31258.24,     4199.04,  7645225.  ,    14641.  ,\n",
       "             441.  ,      784.  ],\n",
       "       [    8930.25,    27423.36,     4070.44,  4112784.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  3869089.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [   10080.16,    34077.16,     4422.25, 10863616.  ,    23104.  ,\n",
       "             289.  ,      484.  ],\n",
       "       [    8930.25,    28968.04,     4070.44,  4096576.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [    9820.81,    34819.56,     4422.25,  7884864.  ,    25600.  ,\n",
       "             361.  ,      676.  ],\n",
       "       [    8930.25,    27324.09,     4070.44,  3678724.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [    8667.61,    27822.24,     4121.64,  3802500.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9880.36,    31187.56,     4408.96,  7974976.  ,    13225.  ,\n",
       "             324.  ,      484.  ],\n",
       "       [    9820.81,    34819.56,     4422.25,  7263025.  ,    12100.  ,\n",
       "             441.  ,      784.  ],\n",
       "       [    9467.29,    29480.89,     4290.25,  5175625.  ,     7225.  ,\n",
       "             729.  ,     1156.  ],\n",
       "       [   10670.89,    30485.16,     4173.16,  6426225.  ,     7744.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [   11004.01,    30625.  ,     4369.21,  7128900.  ,    14400.  ,\n",
       "             361.  ,      729.  ],\n",
       "       [   10588.41,    33672.25,     4583.29,  9096256.  ,    25921.  ,\n",
       "             361.  ,      576.  ],\n",
       "       [    9682.56,    31046.44,     4303.36,  7177041.  ,    13456.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [    9447.84,    30067.56,     4251.04,  5400976.  ,     9409.  ,\n",
       "             729.  ,     1156.  ],\n",
       "       [    9158.49,    27655.69,     4147.36,  4330561.  ,     4900.  ,\n",
       "             900.  ,     1369.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  3519376.  ,     4624.  ,\n",
       "            1369.  ,     1681.  ],\n",
       "       [    9761.44,    31612.84,     4422.25,  5688225.  ,     7056.  ,\n",
       "             676.  ,     1024.  ],\n",
       "       [   10878.49,    35645.44,     4515.84,  8614225.  ,    12996.  ,\n",
       "             576.  ,      784.  ],\n",
       "       [    9682.56,    31046.44,     4303.36,  7365796.  ,    13456.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [   11642.41,    34856.89,     4678.56,  9455625.  ,     9025.  ,\n",
       "             361.  ,      576.  ],\n",
       "       [   10878.49,    35645.44,     4515.84,  9205156.  ,    12996.  ,\n",
       "             529.  ,      784.  ],\n",
       "       [   10241.44,    31258.24,     4199.04,  5736025.  ,    10201.  ,\n",
       "             529.  ,      841.  ],\n",
       "       [    9158.49,    28798.09,     4044.96,  9672100.  ,     3844.  ,\n",
       "             729.  ,     1024.  ],\n",
       "       [    9840.64,    31862.25,     4610.41,  9853321.  ,    25600.  ,\n",
       "             361.  ,      625.  ],\n",
       "       [    9761.44,    31612.84,     4422.25,  5688225.  ,     7056.  ,\n",
       "             676.  ,     1024.  ],\n",
       "       [    9467.29,    29480.89,     4290.25,  5125696.  ,     2704.  ,\n",
       "            1369.  ,     2116.  ],\n",
       "       [    8930.25,    28459.69,     4096.  ,  4704561.  ,     4900.  ,\n",
       "             841.  ,     1156.  ],\n",
       "       [    9158.49,    27655.69,     4147.36,  5175625.  ,     3136.  ,\n",
       "            1156.  ,     1296.  ],\n",
       "       [    8779.69,    24932.41,     4044.96,  4494400.  ,     5329.  ,\n",
       "             676.  ,      961.  ],\n",
       "       [    9273.69,    29929.  ,     4277.16,  5616900.  ,    13456.  ,\n",
       "             529.  ,      900.  ],\n",
       "       [   10080.16,    34077.16,     4422.25,  9363600.  ,    23104.  ,\n",
       "             361.  ,      625.  ],\n",
       "       [    9447.84,    29584.  ,     4277.16,  4601025.  ,     6724.  ,\n",
       "            1024.  ,     1369.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  4528384.  ,    10404.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [    8930.25,    28459.69,     4096.  ,  4857616.  ,     4900.  ,\n",
       "             841.  ,     1156.  ],\n",
       "       [   12100.  ,    36442.81,     4942.09, 12355225.  ,    15129.  ,\n",
       "             484.  ,      625.  ],\n",
       "       [    7814.56,    19909.21,     3636.09,  2214144.  ,     2304.  ,\n",
       "            2209.  ,     2809.  ],\n",
       "       [    8649.  ,    24743.29,     4070.44,  4601025.  ,    10404.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [   10670.89,    30485.16,     4173.16,  6426225.  ,     7744.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [   10920.25,    35268.84,     4422.25,  9803161.  ,    24336.  ,\n",
       "             400.  ,      576.  ],\n",
       "       [   10485.76,    30835.36,     4422.25,  5827396.  ,     8464.  ,\n",
       "             729.  ,     1024.  ],\n",
       "       [   10485.76,    30835.36,     4422.25,  6041764.  ,     8464.  ,\n",
       "             729.  ,     1024.  ],\n",
       "       [    8779.69,    24743.29,     4147.36,  3678724.  ,     4624.  ,\n",
       "            1369.  ,     1681.  ],\n",
       "       [    9312.25,    24680.41,     4083.21,  4096576.  ,     5776.  ,\n",
       "             900.  ,     1156.  ],\n",
       "       [    9273.69,    29721.76,     4277.16,  5784025.  ,     7744.  ,\n",
       "             625.  ,     1024.  ],\n",
       "       [   10485.76,    30835.36,     4422.25,  6150400.  ,     5329.  ,\n",
       "             900.  ,     1089.  ],\n",
       "       [    9761.44,    31612.84,     4422.25,  5880625.  ,     7056.  ,\n",
       "             676.  ,     1024.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  3869089.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9196.81,    29998.24,     4395.69,  7901721.  ,    21025.  ,\n",
       "             361.  ,      576.  ],\n",
       "       [    8930.25,    27324.09,     4070.44,  3568321.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [   11902.81,    35645.44,     4747.21,  8714304.  ,    12996.  ,\n",
       "             529.  ,      784.  ],\n",
       "       [    9467.29,    29480.89,     4290.25,  4892944.  ,     7225.  ,\n",
       "             729.  ,     1156.  ],\n",
       "       [    9447.84,    30067.56,     4251.04,  5299204.  ,     9409.  ,\n",
       "             729.  ,     1156.  ],\n",
       "       [    8779.69,    24617.61,     4019.56,  4202500.  ,     4761.  ,\n",
       "             961.  ,     1296.  ],\n",
       "       [   11193.64,    37133.29,     5097.96,  8088336.  ,    12100.  ,\n",
       "             361.  ,      625.  ],\n",
       "       [   11902.81,    35645.44,     4733.44,  9296401.  ,    25600.  ,\n",
       "             361.  ,      625.  ],\n",
       "       [    8930.25,    27324.09,     4070.44,  3884841.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [    9273.69,    29721.76,     4277.16,  5593225.  ,     7744.  ,\n",
       "             625.  ,     1024.  ],\n",
       "       [    9158.49,    27655.69,     4147.36,  4579600.  ,     4900.  ,\n",
       "             784.  ,     1156.  ],\n",
       "       [    9158.49,    28798.09,     4044.96,  5198400.  ,     3844.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [    8779.69,    22500.  ,     4096.  ,  3825936.  ,     5776.  ,\n",
       "             900.  ,     1156.  ],\n",
       "       [   10241.44,    31258.24,     4199.04,  7344100.  ,    14641.  ,\n",
       "             441.  ,      784.  ],\n",
       "       [    8930.25,    27456.49,     4096.  ,  4932841.  ,     8100.  ,\n",
       "             576.  ,      841.  ],\n",
       "       [    9158.49,    27655.69,     4147.36,  4384836.  ,     4900.  ,\n",
       "            1444.  ,     2209.  ],\n",
       "       [    9409.  ,    29584.  ,     4277.16,  5688225.  ,     6724.  ,\n",
       "             576.  ,      625.  ],\n",
       "       [   10241.44,    31258.24,     4199.04,  5736025.  ,    10201.  ,\n",
       "             529.  ,      841.  ],\n",
       "       [    9682.56,    31046.44,     4303.36,  6431296.  ,    13456.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [   11664.  ,    34856.89,     4664.89,  9796900.  ,    20164.  ,\n",
       "             324.  ,      576.  ],\n",
       "       [   10878.49,    35645.44,     4515.84,  9253764.  ,    12996.  ,\n",
       "             576.  ,      784.  ],\n",
       "       [    9312.25,    26699.56,     4096.  ,  4040100.  ,     5776.  ,\n",
       "             900.  ,     1156.  ],\n",
       "       [    9467.29,    29480.89,     4290.25,  5377761.  ,     4624.  ,\n",
       "            1369.  ,     1764.  ],\n",
       "       [    9682.56,    31046.44,     4303.36,  8850625.  ,    13456.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  3956121.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    8930.25,    24304.81,     4044.96,  3511876.  ,     4900.  ,\n",
       "            1444.  ,     1849.  ],\n",
       "       [   11384.89,    35156.25,     4942.09, 12215025.  ,    15129.  ,\n",
       "             484.  ,      625.  ],\n",
       "       [    9820.81,    34819.56,     4422.25,  7606564.  ,    12100.  ,\n",
       "             441.  ,      784.  ],\n",
       "       [    9467.29,    29480.89,     4290.25,  4879681.  ,     7225.  ,\n",
       "             729.  ,     1156.  ],\n",
       "       [    9158.49,    25185.69,     4044.96,  4060225.  ,     3844.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9761.44,    31612.84,     4422.25,  5808100.  ,     7056.  ,\n",
       "             676.  ,     1024.  ],\n",
       "       [    9273.69,    29721.76,     4277.16,  5774409.  ,    13456.  ,\n",
       "             529.  ,      900.  ],\n",
       "       [    8930.25,    27324.09,     4070.44,  4068289.  ,     3025.  ,\n",
       "            2025.  ,     2500.  ],\n",
       "       [    8779.69,    24743.29,     4147.36,  4016016.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9273.69,    29721.76,     4277.16,  5774409.  ,    13456.  ,\n",
       "             529.  ,      900.  ],\n",
       "       [    9409.  ,    30102.25,     4277.16,  5244100.  ,     6724.  ,\n",
       "             784.  ,     1024.  ],\n",
       "       [    9820.81,    34819.56,     4422.25,  7064964.  ,    12100.  ,\n",
       "             441.  ,      784.  ],\n",
       "       [    9682.56,    31046.44,     4303.36,  6451600.  ,    13456.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [   11642.41,    34856.89,     4678.56,  9455625.  ,     9409.  ,\n",
       "             361.  ,      576.  ],\n",
       "       [    9761.44,    31612.84,     4422.25,  5808100.  ,     7056.  ,\n",
       "             676.  ,     1024.  ],\n",
       "       [    9158.49,    25185.69,     4044.96,  3940225.  ,     3844.  ,\n",
       "            1225.  ,     1521.  ],\n",
       "       [    9467.29,    29480.89,     4290.25,  5112121.  ,     2704.  ,\n",
       "            1369.  ,     2116.  ],\n",
       "       [    9158.49,    25185.69,     4044.96,  4161600.  ,     3844.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9312.25,    30765.16,     4251.04,  5308416.  ,     7396.  ,\n",
       "             729.  ,     1089.  ],\n",
       "       [    8779.69,    24743.29,     4070.44,  4528384.  ,    10404.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [    8667.61,    25312.81,     4121.64,  3629025.  ,     4624.  ,\n",
       "             961.  ,     1444.  ],\n",
       "       [    9331.56,    32508.09,     4970.25, 13579225.  ,    24025.  ,\n",
       "             256.  ,      324.  ],\n",
       "       [    9273.69,    29929.  ,     4277.16,  5419584.  ,     7744.  ,\n",
       "             625.  ,     1024.  ],\n",
       "       [   10878.49,    35645.44,     4515.84,  8479744.  ,    12996.  ,\n",
       "             529.  ,      784.  ],\n",
       "       [   10588.41,    33672.25,     4583.29,  8856576.  ,    25921.  ,\n",
       "             400.  ,      576.  ],\n",
       "       [    9682.56,    31046.44,     4303.36,  6507601.  ,    13456.  ,\n",
       "             576.  ,      900.  ],\n",
       "       [    7499.56,    20909.16,     4083.21,  2934369.  ,     3364.  ,\n",
       "            2401.  ,     2916.  ],\n",
       "       [    9044.01,    26373.76,     4070.44,  4032064.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [   11902.81,    35645.44,     4747.21,  9072144.  ,    17956.  ,\n",
       "             324.  ,      529.  ],\n",
       "       [    9389.61,    30136.96,     4277.16,  7022500.  ,    12321.  ,\n",
       "             529.  ,      529.  ],\n",
       "       [    8930.25,    28968.04,     4070.44,  4149369.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [   11642.41,    34856.89,     4678.56, 10220809.  ,     9025.  ,\n",
       "             784.  ,     1089.  ],\n",
       "       [    8930.25,    27324.09,     4070.44,  3806401.  ,     4761.  ,\n",
       "             961.  ,     1369.  ],\n",
       "       [   11642.41,    34856.89,     4678.56, 10575504.  ,     9025.  ,\n",
       "             784.  ,     1089.  ],\n",
       "       [    9158.49,    27655.69,     4147.36,  5175625.  ,     3136.  ,\n",
       "            1444.  ,     2209.  ],\n",
       "       [   10485.76,    30835.36,     4422.25,  5410276.  ,     8464.  ,\n",
       "             841.  ,     1156.  ],\n",
       "       [   11642.41,    34856.89,     4678.56,  9120400.  ,     9409.  ,\n",
       "             361.  ,      576.  ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.hstack((x_train**2,x_train_5thcolumn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_5thcolumn=x_test[:,5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test[:,[0,1,2,4,9,11,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.hstack((x_test**2,x_test_5thcolumn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8418476706940167\n",
      "Test Score: 0.8620860606701146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor_after_removed_PLR=LinearRegression() \n",
    "regressor_after_removed_PLR.fit(x_train,y_train)\n",
    "print(\"Train Score:\",regressor_after_removed_PLR.score(x_train,y_train))\n",
    "print(\"Test Score:\",regressor_after_removed_PLR.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [[88**2,167**2,1500**2,120**2,50**2,70**2,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
